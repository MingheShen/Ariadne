<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description" content="Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries">
    <meta property="og:title" content="Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries" />
    <meta property="og:url" content="https://github.com/MingheShen/Ariadne/" />
    <meta property="og:image" content="" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <title>Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries</title>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">
                            Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries
                        </h1>
                        <div class="is-size-5 publication-authors">
                          <span class="author-block">Minghe Shen<sup>1</sup>,</span>
                          <span class="author-block">Zhuo Zhi<sup>1</sup>,</span>
                          <span class="author-block">Chonghan Liu<sup>2</sup>,</span>
                          <br>
                          <span class="author-block">Shuo Xing<sup>3</sup>,</span>
                          <span class="author-block">Zhengzhong Tu<sup>3</sup>,</span>
                          <span class="author-block">Che Liu<sup>4</sup></span>
                      </div>                      
                      
                      <div class="is-size-5 publication-authors">
                          <span class="author-block">
                              <sup>1</sup>University College London, <sup>2</sup>University of California, Los Angeles, <sup>3</sup>Texas A&M University,
                              <br><sup>4</sup>Imperial College London
                          </span>
                          <br>
                          <span class="author-block">Corresponding to:</span>
                          <span class="author-block">
                              <a href="mailto:che.liu21@imperial.ac.uk">che.liu21@imperial.ac.uk</a>
                          </span>
                      </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- GitHub link -->
                                <span class="link-block">
                                    <a href="https://github.com/MingheShen/Ariadne" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>Code</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2511.00710" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="ai ai-arxiv"></i>
                                    </span>
                                    <span>Paper</span>
                                    </a>
                                </span>

                                <span class="link-block">
                                  <a href="https://huggingface.co/KOKKKOKK/Ariadne" target="_blank"
                                  class="external-link button is-normal is-rounded is-dark">
                                      <span class="icon">
                                        ðŸ¤—
                                      </span>
                                      <span>Models</span>
                                  </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container" style="margin-bottom: 2vh;margin-top: -6vh;">
          <!-- Abstract. -->
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Introduction</h2>
              <div class="content has-text-justified">
                <p>
                  While Vision-Language Models (VLMs) post-trained with Reinforcement Learning (RL) show impressive general reasoning, their evaluation is often confined to language-dominant tasks (e.g., math). This raises a critical question: can RL post-training truly extend the inherent capability boundary of a base VLM, particularly for visual-centric spatial tasks where it initially fails? To investigate this, we introduce Ariadne, a framework utilizing synthetic mazes for multi-step spatial reasoning where task difficulty (e.g., path length, turns) is precisely controlled. We leverage this controllable environment to train VLMs using Reinforcement Learning with Verified Rewards (RLVR) in a difficulty-aware curriculum. Surprisingly, post-RLVR training, the VLM achieves over 50% accuracy on a problem set where the base model scored 0%, demonstrating that our approach expands the model's initial capability boundary. To assess real-world viability, we evaluate out-of-distribution (OOD) generalization on practical benchmarks. Despite training only on synthetic maze samples, Ariadne achieves significant zero-shot improvements, averaging 16% on MapBench (e.g., museum navigation) and 24% on ReasonMap (subway transfer tasks). These results confirm that our method not only broadens the model's fundamental limits but also enhances its generalization to real-world spatial reasoning. We acknowledge our study is limited to the post-training phase, given the opaqueness of pre-training data, and hope our research motivates further work on specialized, capability-extending alignment.
				</p>
              </div>
            </div>
          </div>
          <!--/ Abstract. -->
      </div>
    </section>

    <section class="hero is-light is-small">
        <div class="hero-body has-text-centered">
          <h1 class="title is-1 acecoder">
            <span class="acecoder">Ariadne</span>
          </h1>
        </div>
    </section>

    <section class="section">
        <div class="container">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">RLVR Enables VLMs to Break Reasoning Boundaries</h2>
              <div class="content has-text-justified">
                <p>
					The reward trajectory during GRPO training on AlphaMaze, along with quantitative evaluations on the test set. Across all evaluated movement step ranges, Ariadne shows a consistent advantage over its base model, Qwen2.5-VL-7B-Instruct. For Qwen2.5-VL-7B-Instruct, we perform eight rollouts to confirm model stability and observe that performance drops to zero when the path requires three movement steps or three turns, which we define as the modelâ€™s reasoning boundary. After RLVR training, Ariadneâ€™s success rate rises to over 50% on 3 step cases and over 10% on 3 turn cases, and the collapse point shifts from 3 to 5, indicating that RLVR effectively extends the modelâ€™s reasoning boundary to more complex path configurations.
                </p>
                <div class="box m-5">
                    <div class="content has-text-centered">
                      <img src="static/images/train.png" alt="main" class="center" width="100%"/>
                    </div>
                  </div>
              </div>
            </div>
          </div>
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">RLVR Extends VLM Reasoning to Real-world Tasks</h2>
              <div class="content has-text-justified">
                <p>
					Ariadne achieves strong performance on MapBench and ReasonMap. The model generalizes well across diverse spatial layouts, from unstructured outdoor networks to structured indoor grids, and demonstrates clear gains in long-horizon, multi-turn reasoning. These improvements are most apparent under high path complexity and extended reasoning chains, where instruction-tuned baselines degrade notably. Together, the results suggest that GRPO training on synthetic maze data effectively enhances spatial-visual reasoning, improving the modelâ€™s capability to handle complex real-world tasks.
                </p>
                <div class="box m-5">
                  <div class="content has-text-centered">
                    <img src="static/images/results.png" alt="main" class="center" width="100%"/>
                  </div>
                </div>
              </div>
            </div>
          </div>

          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Explore More</h2>
              <div class="content has-text-justified">
                <p>
                    Explore more about the details of our approach, analysis, and insights within <a href="https://arxiv.org/abs/2511.00710">our paper</a>!
                </p>
                
              </div>
            </div>
          </div>

        </div>
      </section>

	<!-- BibTeX citation -->
	<section class="section" id="BibTeX">
	    <div class="container is-max-desktop content">
	        <h2 class="title">Reference</h2>
	        If you find our work useful, please give us a free cite:
	        <pre><code>
			@article{ariadne,
			      title={Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries},
			      author = {Minghe Shen and Zhuo Zhi and Chonghan Liu and Shuo Xing and Zhengzhong Tu and Che Liu},
			      journal={arXiv preprint arXiv: 2511.00710},
			      year={2025}
			}
	        </code></pre>
	    </div>
	</section>

	<footer class="footer">
	    <div class="container">
	        <div class="columns is-centered">
	            <div class="column is-8">
	                <div class="content has-text-centered">
	                    <p>
	                        This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
	                    </p>
	                </div>
	            </div>
	        </div>
	    </div>
	</footer>

</body>
</html>
